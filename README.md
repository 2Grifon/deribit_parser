## Развёртка, управление проектом

### Клонирование репозитория
`git clone git@gitlab.com:MintMarmot/deribit_parser.git`

### Запуск проекта
1. Убедиться что в проекте присутствует корректный **.env** файл с необходимыми настройками
2. Перейти в каталог с [makefile](Makefile), т.е. корень проекта
3. Использовать команду `make rebuild` для сборки проекта и запуска контейнеров
4. Испрользовать команду `make upgrade` для применения миграций и создания БД

### Настройки .env файла
- **Пример пустого .env файла**
 [default.env](default.env)

- **Fast API**
  - `CORS_ORIGIN_WHITELIST` - список URL, с которых разрешены запросы с CSRF токенами. Пример: `https://somedomain.ru`

- **Postgres** - все настройки этого пункта будут использованы при первом создании БД, не рекомендуется изменять после создания базы
  - `POSTGRES_DB` - имя базы данных на сервере, в которой будут храниться все табилцы созданные по моделям джанго. Пример: `postgres`
  - `POSTGRES_USER` - имя пользователя с доступом к БД из пункта `POSTGRES_DB`. Пример: `postgres`
  - `POSTGRES_PASSWORD` - пароль от пользователя, можно использовать любой безопасный случайный пароль
  - `POSTGRES_HOST` - название сервера базы данных. По умолчанию должен быть: `postgres`

- **Rabbit** - не обязателен для настройки, параметры по умолчанию установлены в [config.py](backend/app/core/config.py)
  - `RABBITMQ_PROTOCOL` - протокол, должен быть `ampq`.
  - `RABBITMQ_HOST` - имя сервиса RabbitMQ в docker-compose, должен быть `rabbitmq`).
  - `RABBITMQ_PORT` - порт RabbitMQ, обычно `5672`.
  - `RABBITMQ_USER` - пользователь. Пример: `guest`
  - `RABBITMQ_PASSWORD` - пароль. Пример: `guest`

### Команды make
 - **build** - сборка образа проекта
 - **rebuild** - пересборка проекта
 - **up** - запуск проекта
 - **down** - остановка проекта
 - **reup** - перезапуск проекта
 - **alembic** - запускает alembic <args> внутри backend контейнера
 - **autogenerate m="msg"** - создаёт миграцию
 - **upgrade** - применяет миграции
 - **downgrade** - откат на одну миграцию

### Файловая структура
- **backend/** - основной сервис Python
  - **app/** - основное приложение
    - **core/** - конфигурация приложения, подключение к БД, базовые классы и утилиты
    - **models/** - SQLModel модели
    - **routes/** - API-маршруты
    - **tasks/** - Celery задачи
    - **integrations/** - внешние интеграции с API
    - Файл [**main.py**](backend/app/main.py) - точка входа FastAPI
  - **alembic/** - конфигурация Alembic
    - **versions/** папка для хранения миграций
- **docker-compose.yml** - конфиг сервисов проекта
- **Makefile** - часто используемые команды для сборки, запуска и миграций
- **default.env** - пример переменных окружения


### Design decisions
- **Файловая структура** - Отталкивался изначально от шаблонного проекта FasAPI(https://github.com/fastapi/full-stack-fastapi-template/tree/master/backend), с изменениями соответсвующими масштабу проекта. Текущую структуру можно довольно легко масштабировать, если надо (гипотетически) добавить новый сервис Python, например отдельный django бэкенд, tg бота или ещё что-то. Само приложение app тоже можно масштабировать, легко добавить новые файлы моделей или роуты, если появилась бы новая логика, то текущие файлы моделей, роутов, тасок и т.д. можно перетащить в новую директорию и устроить структуру похожу на django приоложения

- [**pyproject.toml**](backend/pyproject.toml) - Удобный способ конфигурации сервиса, все зависимости указаны в нём, поэтому не использую requirements.txt. Линтеры указаны в опциональных пакетах, т.к. не нужны при сборке контейнера.

- **Асинхронный клиент SQLAlchemy и использование SQLModel** - Для моделей я использую SQLModel, потому что она прекрасно интегрируется с FastAPI и Alembic. К сожалению, я не нашёл удобной поддежики асинхронного engine прямо в SQLModel, а асинхронное api FastAPI не особенно полезно с синхронной ORM, так что в файле конфигурации БД [db.py](backend/app/core/db.py) я создаю асинхронный engine и зависимость FastAPI (SessionDep) при помощи create_async_engine из sqlalchemy (SQLModel основан на SQLAlchemy) а не пользуюсь SQLModel в чистом виде. Зависимость я потом отдаю всем роутам API. Отдельно я создаю синхронный engine для использования его в моих задачах celery, т.к. они синхронные.

- **Класс доступа к API deribit** - Для получения цен валют нужен всего один роут API, можно наверное было ограничиться функцией, но я написал отдельный класс для доступа к API deribit, чтоб в гипотетической ситуации, где парсер надо будет расширять, это было сделать проще и все методы работы с API находились в одном удобном классе.

- **Роуты API** - в ТЗ указано было 3 метода API, я реализовал два роута. Первый(/api/prices/last), отдаёт один объект с последней ценой валюты по тикеру. Второй(/api/prices/
) - отдаёт полный список цен по указаной валюте, и, принимает в себя опциоальные параметры для ограничения выборки по дате в UNIX, покрывая собой функционал 2-х методой из ТЗ ("Получение всех сохраненных данных по указанной валюте" и "Получение цены валюты с фильтром по дате") 

- **Alembic** - совместим с SQLAlchemy/SQLModel, которые в свою очередь хорошо совместимы с FastAPI. Поддерживает автогенерацию миграций, их применение к базе, откат, в целом, всё не обходимое для менеджмента миграций библиотека выполняет и удобна в использовании.
